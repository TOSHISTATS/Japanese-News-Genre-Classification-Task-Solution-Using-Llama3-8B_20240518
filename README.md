# Llama3-8Bによるlivedoor-newsデータを用いたニュース・タイトルの9クラス判別問題 / Japanese-News-Genre-Classification-Task-Solution-Using-Llama3-8B_20240520





![Screenshot 2024-05-20 12 57 52](https://github.com/TOSHISTATS/Japanese-News-Genre-Classification-Task-Solution-Using-Llama3-8B_20240520/assets/28681557/137773a3-4960-4e7a-a4cb-0f9837dfde16)





![Screenshot 2024-05-20 12 58 03](https://github.com/TOSHISTATS/Japanese-News-Genre-Classification-Task-Solution-Using-Llama3-8B_20240520/assets/28681557/d66808d9-8f89-4588-b0dc-8243b987f6cf)


livedoor-newsデータを用いた9クラスのニュース・タイトル判別問題を Llama3-8Bでそれぞれ90%超の精度を達成
Achieve more than 90% accuracy with Llama3-8B  for 9 class-newstitle-classification problem using livedoor-news data
BERT, or Bidirectional Encoder Representations from Transformers by Google, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.

finetuned with data of livedoor news corpus for 5 classes (training 3503 samples, test 826 samples)



(1) livedoor news corpus https://www.rondhuit.com/download.html#ldcc
CC BY-ND 2.1 JP https://creativecommons.org/licenses/by-nd/2.1/jp/


Copyright © 2024 ToshiStats Co.,Ltd. All right reserved

This code is solely for educational purposes. 

Notice: ToshiStats Co., Ltd. and I do not accept any responsibility or liability for loss or damage occasioned to any person or property through using materials, instructions, methods, algorithms or ideas contained herein, or acting or refraining from acting as a result of such use. ToshiStats Co., Ltd. and I expressly disclaim all implied warranties, including merchantability or fitness for any particular purpose. There will be no duty on ToshiStats Co., Ltd. and me to correct any errors or defects in the codes and the software.
